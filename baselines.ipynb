{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e95fcf98",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b9d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV, LassoCV # lasso is linear model with L1 regularization\n",
    "from sklearn.metrics import f1_score, brier_score_loss\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import scipy\n",
    "from scipy.stats import ks_2samp, mannwhitneyu\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8cebcd",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af6bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "REPEATS = 5\n",
    "FOLDS = 5 \n",
    "\n",
    "train_q = pd.read_excel(\"data/TRAIN/TRAIN_QUANTITATIVE_METADATA.xlsx\")\n",
    "train_c = pd.read_excel(\"data/TRAIN/TRAIN_CATEGORICAL_METADATA.xlsx\")\n",
    "test_q = pd.read_excel(\"data/TEST/TEST_QUANTITATIVE_METADATA.xlsx\")\n",
    "test_c = pd.read_excel(\"data/TEST/TEST_CATEGORICAL_METADATA.xlsx\")\n",
    "\n",
    "train_combined = pd.merge(train_q, train_c, on='participant_id', how='left').set_index(\"participant_id\")\n",
    "test_combined = pd.merge(test_q, test_c, on='participant_id', how='left').set_index(\"participant_id\")\n",
    "\n",
    "labels = pd.read_excel(\"data/TRAIN/TRAINING_SOLUTIONS.xlsx\").set_index(\"participant_id\")\n",
    "\n",
    "train_combined = train_combined.sort_index()\n",
    "labels = labels.sort_index()\n",
    "assert all(train_combined.index == labels.index), \"Label IDs do not match train IDs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760d7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_counts = train_combined.isna().sum()\n",
    "total_nans = nan_counts[nan_counts > 0]\n",
    "print(\"Columns with NaN values:\\n\", total_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6356c268",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_combined.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bb2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    \"Basic_Demos_Study_Site\", \"MRI_Track_Scan_Location\", \"PreInt_Demos_Fam_Child_Ethnicity\",\n",
    "    \"PreInt_Demos_Fam_Child_Race\", 'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Occ',\n",
    "]\n",
    "\n",
    "train_combined = train_combined.drop(columns=drop_cols)\n",
    "test_combined = test_combined.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441116db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "train_combined = pd.DataFrame(\n",
    "    scaler.fit_transform(train_combined),\n",
    "    columns=train_combined.columns,\n",
    "    index=train_combined.index,\n",
    ")\n",
    "\n",
    "test_combined = pd.DataFrame(\n",
    "    scaler.transform(test_combined),\n",
    "    columns=test_combined.columns,\n",
    "    index=test_combined.index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c997e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(estimator=LassoCV(random_state=SEED), max_iter=5, random_state=SEED)\n",
    "train_combined[:] = imputer.fit_transform(train_combined)\n",
    "test_combined[:] = imputer.transform(test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7551b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_adhd = labels['ADHD_Outcome']\n",
    "y_sex = labels[\"Sex_F\"]\n",
    "combinations = y_adhd.astype(str) + y_sex.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d5649",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a4d5e",
   "metadata": {},
   "source": [
    "# 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27ff32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sex = [\n",
    "       'EHQ_EHQ_Total', 'ColorVision_CV_Score', 'APQ_P_APQ_P_CP',\n",
    "       'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD',\n",
    "       'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP', 'SDQ_SDQ_Conduct_Problems',\n",
    "       'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems',\n",
    "       'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Generating_Impact',\n",
    "       'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing',\n",
    "       'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial', 'MRI_Track_Age_at_Scan',\n",
    "       'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P2_Edu'\n",
    "]\n",
    "\n",
    "features_adhd = [\n",
    "       'EHQ_EHQ_Total', 'ColorVision_CV_Score', 'APQ_P_APQ_P_CP',\n",
    "       'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD',\n",
    "       'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP', 'SDQ_SDQ_Conduct_Problems',\n",
    "       'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems',\n",
    "       'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Generating_Impact',\n",
    "       'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing',\n",
    "       'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial', 'MRI_Track_Age_at_Scan',\n",
    "       'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P2_Edu', 'sex_proba',\n",
    "       'I_APQ_P_APQ_P_INV', 'I_APQ_P_APQ_P_PP', 'I_SDQ_SDQ_Hyperactivity',\n",
    "       'I_MRI_Track_Age_at_Scan', 'I_SDQ_SDQ_Generating_Impact'\n",
    "]\n",
    "\n",
    "# Features to be interacted with predicted probability of Sex_F = 1\n",
    "interactions = [\n",
    "    \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_PP\", \"SDQ_SDQ_Hyperactivity\", \n",
    "    \"MRI_Track_Age_at_Scan\", \"SDQ_SDQ_Generating_Impact\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63643d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(y_true, y_pred, weights, label=\"None\", threshold=0.5):\n",
    "    brier = brier_score_loss(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, (y_pred > threshold).astype(int), sample_weight=weights)\n",
    "    print(f\"{label} -> Brier Score: {brier:.4f}, F1: {f1:.4f}\")\n",
    "    return brier, f1\n",
    "\n",
    "# store oof brier and f1\n",
    "scores_sex = []\n",
    "scores_adhd = []\n",
    "\n",
    "# store oof predictions for diagnostics and threshold optimization\n",
    "sex_oof = np.zeros(len(y_sex))\n",
    "adhd_oof = np.zeros(len(y_adhd))\n",
    "\n",
    "# classification thresholds\n",
    "t_sex = 0.3\n",
    "t_adhd = 0.4\n",
    "\n",
    "# Repeated Stratified K-Fold\n",
    "rskf = RepeatedStratifiedKFold(n_splits=FOLDS, n_repeats=REPEATS, random_state=SEED)\n",
    "# skf for LogisticRegressionCV\n",
    "skf = StratifiedKFold(n_splits=FOLDS)\n",
    "\n",
    "# L1-regularized logistic regression with cross-validation.\n",
    "params_1 = {\n",
    "    \"penalty\":\"l1\", \n",
    "    \"Cs\": 10,   # number of C values to test (inverse of regularization strength)\n",
    "    \"cv\":skf,   # internal CV for model selection\n",
    "    \"fit_intercept\":True, \n",
    "    \"scoring\": \"f1\", # choose C based on best F1 score\n",
    "    \"random_state\": SEED, \n",
    "    \"solver\": \"saga\"  # supports l1 + multinomial\n",
    "}\n",
    "\n",
    "params_2 = {\n",
    "    \"penalty\":\"l1\", \n",
    "    \"Cs\": 10, \n",
    "    \"cv\":skf, \n",
    "    \"fit_intercept\":True, \n",
    "    \"scoring\": \"f1\", \n",
    "    \"random_state\": SEED, \n",
    "    \"solver\": \"saga\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c3263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = LogisticRegressionCV(**params_1)\n",
    "model_2 = LogisticRegressionCV(**params_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b954aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(rskf.split(train_combined, combinations), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_val = train_combined.iloc[train_idx], train_combined.iloc[val_idx]\n",
    "    y_train_adhd, y_val_adhd = y_adhd.iloc[train_idx], y_adhd.iloc[val_idx]\n",
    "    y_train_sex, y_val_sex = y_sex.iloc[train_idx], y_sex.iloc[val_idx]\n",
    "    # 2x weight for Sex_F == 1 and ADHD_Outcome == 1 (as mentioned in competition evaluation)\n",
    "    weights_train = np.where(combinations.iloc[train_idx]==\"11\", 2, 1)\n",
    "    weights = np.where(combinations.iloc[val_idx]==\"11\", 2, 1)\n",
    "    \n",
    "    # Sex_F predictions\n",
    "    model_1.fit(X_train[features_sex], y_train_sex, sample_weight=weights_train) # predict proability of being female\n",
    "    sex_train = model_1.predict_proba(X_train[features_sex])[:, 1]\n",
    "    sex_val = model_1.predict_proba(X_val[features_sex])[:, 1]\n",
    "    sex_oof[val_idx] += sex_val / REPEATS # diagnostic purposes\n",
    "    \n",
    "    # evaluate sex recognition performance\n",
    "    sex_brier, sex_f1 = eval_metrics(y_val_sex, sex_val, weights, \"Sex_F\", threshold=t_sex)\n",
    "    scores_sex.append((sex_brier, sex_f1))\n",
    "    \n",
    "    # Outcome_ADHD prediction\n",
    "    X_train[\"sex_proba\"] = sex_train\n",
    "    X_val[\"sex_proba\"] = sex_val\n",
    "\n",
    "    # adding interactions between predicted sex and other features -> helps ADHD model capture dependency on predicted sex\n",
    "    for interaction in interactions:\n",
    "        X_train[f\"I_{interaction}\"] = X_train[interaction] * X_train[\"sex_proba\"]\n",
    "        X_val[f\"I_{interaction}\"] = X_val[interaction] * X_val[\"sex_proba\"]\n",
    "\n",
    "    # Logistic Regression with L1 penalty\n",
    "    model_2.fit(X_train[features_adhd], y_train_adhd, sample_weight=weights_train)\n",
    "    \n",
    "    adhd_val = model_2.predict_proba(X_val[features_adhd])[:, 1]\n",
    "    adhd_oof[val_idx] += adhd_val / REPEATS\n",
    "    \n",
    "    # evaluate ADHD performance\n",
    "    adhd_brier, adhd_f1 = eval_metrics(y_val_adhd, adhd_val, weights, \"Outcome ADHD\", threshold=t_adhd)\n",
    "    scores_adhd.append((adhd_brier, adhd_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12841510",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== CV Results ===\")\n",
    "print(f\"Sex Mean Brier Score: {np.mean([s[0] for s in scores_sex]):.4f}\")\n",
    "print(f\"Sex Mean F1: {np.mean([s[1] for s in scores_sex]):.4f}\")\n",
    "print(f\"ADHD Mean Brier Score: {np.mean([s[0] for s in scores_adhd]):.4f}\")\n",
    "print(f\"ADHD Mean F1: {np.mean([s[1] for s in scores_adhd]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9391fe67",
   "metadata": {},
   "source": [
    "# 4. Threshold Optimization\n",
    "\n",
    "We are tuning classficaiton thresholds to maximize the F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061d557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ((y_adhd == 1) & (y_sex == 1)) + 1\n",
    "# Compute F1 scores and find the best threshold for sex_oof\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "sex_scores = []\n",
    "for t in tqdm(thresholds, desc=\"Sex Thresholds\"):\n",
    "    tmp_pred = np.where(sex_oof > t, 1, 0)\n",
    "    tmp_score = f1_score(y_sex, tmp_pred, sample_weight=weights)\n",
    "    sex_scores.append(tmp_score)\n",
    "best_sex_threshold = thresholds[np.argmax(sex_scores)]\n",
    "best_sex_score = max(sex_scores)\n",
    "\n",
    "# Compute F1 scores and find the best threshold for adhd_oof\n",
    "adhd_scores = []\n",
    "for t in tqdm(thresholds, desc=\"ADHD Thresholds\"):\n",
    "    tmp_pred = np.where(adhd_oof > t, 1, 0)\n",
    "    tmp_score = f1_score(y_adhd, tmp_pred, sample_weight=weights)\n",
    "    adhd_scores.append(tmp_score)\n",
    "best_adhd_threshold = thresholds[np.argmax(adhd_scores)]\n",
    "best_adhd_score = max(adhd_scores)\n",
    "\n",
    "# Plot results\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10), constrained_layout=True)\n",
    "\n",
    "# Plot F1 scores for sex_oof\n",
    "axs[0, 0].plot(thresholds, sex_scores, label='F1 Score', color='blue')\n",
    "axs[0, 0].scatter(best_sex_threshold, best_sex_score, color='red', label=f'Best: {best_sex_score:.3f} (Threshold: {best_sex_threshold:.2f})')\n",
    "axs[0, 0].set_title('F1 Scores vs Thresholds (Sex)')\n",
    "axs[0, 0].set_xlabel('Threshold')\n",
    "axs[0, 0].set_ylabel('F1 Score')\n",
    "axs[0, 0].legend()\n",
    "\n",
    "# Plot histogram of sex_oof\n",
    "axs[0, 1].hist(sex_oof, bins=30, color='skyblue', edgecolor='black')\n",
    "axs[0, 1].set_title('Distribution of sex_oof')\n",
    "axs[0, 1].set_xlabel('Probability')\n",
    "axs[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Plot F1 scores for adhd_oof\n",
    "axs[1, 0].plot(thresholds, adhd_scores, label='F1 Score', color='orange')\n",
    "axs[1, 0].scatter(best_adhd_threshold, best_adhd_score, color='red', label=f'Best: {best_adhd_score:.3f} (Threshold: {best_adhd_threshold:.2f})')\n",
    "axs[1, 0].set_title('F1 Scores vs Thresholds (ADHD)')\n",
    "axs[1, 0].set_xlabel('Threshold')\n",
    "axs[1, 0].set_ylabel('F1 Score')\n",
    "axs[1, 0].legend()\n",
    "\n",
    "# Plot histogram of adhd_oof\n",
    "axs[1, 1].hist(adhd_oof, bins=30, color='lightgreen', edgecolor='black')\n",
    "axs[1, 1].set_title('Distribution of adhd_oof')\n",
    "axs[1, 1].set_xlabel('Probability')\n",
    "axs[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.suptitle('Threshold Analysis and Distributions', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb625c",
   "metadata": {},
   "source": [
    "# 5. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6a8fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final models and predictions\n",
    "model_1.fit(train_combined[features_sex], y_sex, sample_weight=weights)\n",
    "\n",
    "sex_proba_train = model_1.predict_proba(train_combined[features_sex])[:,1]\n",
    "sex_proba_test = model_1.predict_proba(test_combined[features_sex])[:,1]\n",
    "\n",
    "train_combined[\"sex_proba\"] = sex_proba_train\n",
    "test_combined[\"sex_proba\"] = sex_proba_test\n",
    "\n",
    "for interaction in interactions:\n",
    "    train_combined[f\"I_{interaction}\"] = train_combined[\"sex_proba\"] * train_combined[interaction]\n",
    "    test_combined[f\"I_{interaction}\"] = test_combined[\"sex_proba\"] * test_combined[interaction]\n",
    "\n",
    "model_2.fit(train_combined[features_adhd], y_adhd, sample_weight=weights)\n",
    "\n",
    "adhd_proba_test = model_2.predict_proba(test_combined[features_adhd])[:,1]\n",
    "\n",
    "# Show most important features for model 2 (feature importance) \n",
    "coeffs_2 = pd.DataFrame({\"feature\": features_adhd, \"coeff\": model_2.coef_[0]})\n",
    "coeffs_2.sort_values(by=\"coeff\", key=abs, ascending=False)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e518b4",
   "metadata": {},
   "source": [
    "Compare whether the model behaves similarly on train vs test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91f9f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distributions with improved visuals\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot for Sex predictions\n",
    "ax[0].hist(sex_proba_test, bins=10, alpha=0.5, color='blue', label='Sex Test')\n",
    "ax[0].hist(sex_oof, bins=10, alpha=0.5, color='orange', label='Sex OOF') # If distributions look very different, your model may be overfitting\n",
    "ax[0].set_title('Sex Predictions Distribution')\n",
    "ax[0].set_xlabel('Predicted Probability')\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[0].legend()\n",
    "\n",
    "# Plot for ADHD predictions\n",
    "ax[1].hist(adhd_proba_test, bins=10, alpha=0.5, color='green', label='ADHD Test')\n",
    "ax[1].hist(adhd_oof, bins=10, alpha=0.5, color='red', label='ADHD OOF')\n",
    "ax[1].set_title('ADHD Predictions Distribution')\n",
    "ax[1].set_xlabel('Predicted Probability')\n",
    "ax[1].set_ylabel('Frequency')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2efcad4",
   "metadata": {},
   "source": [
    "You're using two statistical tests to quantify whether the OOF and test distributions differ significantly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f626a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test to compare distributions\n",
    "sex_test_result = ks_2samp(sex_proba_test, sex_oof)\n",
    "adhd_test_result = ks_2samp(adhd_proba_test, adhd_oof)\n",
    "sex_mwu_result = mannwhitneyu(sex_proba_test, sex_oof)\n",
    "adhd_mwu_result = mannwhitneyu(adhd_proba_test, adhd_oof)\n",
    "\n",
    "print(\"Kolmogorov-Smirnov Test and MannWhitneyU Results:\")\n",
    "print(f\"Sex KS Test vs. OOF: Statistic={sex_test_result.statistic:.4f}, p-value={sex_test_result.pvalue:.4f}\")\n",
    "print(f\"Sex MWU Test vs. OOF: Statistic={sex_mwu_result.statistic:.4f}, p-value={sex_mwu_result.pvalue:.4f}\")\n",
    "print(f\"ADHD KS Test vs. OOF: Statistic={adhd_test_result.statistic:.4f}, p-value={adhd_test_result.pvalue:.4f}\")\n",
    "print(f\"ADHD MWU Test vs. OOF: Statistic={adhd_mwu_result.statistic:.4f}, p-value={adhd_mwu_result.pvalue:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b376b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "submission = pd.read_excel(\"data/SAMPLE_SUBMISSION.xlsx\")\n",
    "submission[\"ADHD_Outcome\"] = np.where(adhd_proba_test > best_adhd_threshold, 1, 0)\n",
    "submission[\"Sex_F\"] = np.where(sex_proba_test > best_sex_threshold, 1, 0)\n",
    "# Compare share of predicted labels at thresholds between OOF and Test\n",
    "print(f\"Share ADHD OOF: {np.mean(np.where(adhd_oof > best_adhd_threshold, 1, 0)):.4f} - Share ADHD Test: {submission.ADHD_Outcome.mean():.4f}\")\n",
    "print(f\"Share Sex_F OOF: {np.mean(np.where(sex_oof > best_sex_threshold, 1, 0)):.4f} - Share Sex_F Test: {submission.Sex_F.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89b6804",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
