{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e29a372",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1baa218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee65c049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\", \n",
    "                 header=None, names=['StaAcc', 'DuMon', 'CredHis', 'Purpose', 'CredAmt', 'SavAcc', \\\n",
    "                                     'PreEmpl', 'InsRt', 'PerSta', 'OthDebtor', 'PreRe', 'Property', \\\n",
    "                                     'Age', 'IntPla', 'Housing', 'ExstCredit', 'Job', 'NoMain', 'Phone', 'ForWorker', \"Response\"], \n",
    "                 index_col=None, sep=\" \")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba85691",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5d2818",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e82ebc",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb11d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=['float', 'int']).columns\n",
    "\n",
    "def _plot_numeric_classes(df, col, bins=10, hist=True, kde=True):\n",
    "    if hist:\n",
    "        sns.histplot(df[col], bins=bins, kde=False)\n",
    "    if kde:\n",
    "        sns.kdeplot(df[col], color=\"red\")\n",
    "\n",
    "def _distribution_numeric(df, numeric_cols, row=3, col=3, figsize=(20, 15), bins = 10):\n",
    "    print('number of numeric field: ', len(numeric_cols))\n",
    "    assert row*(col-1) < len(numeric_cols)\n",
    "    plt.figure(figsize = figsize)\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.2, hspace=0.5)\n",
    "    for i in range(1, len(numeric_cols)+1, 1):\n",
    "      try:\n",
    "        plt.subplot(row, col, i)\n",
    "        _plot_numeric_classes(df, numeric_cols[i-1], bins = bins)\n",
    "        plt.title(numeric_cols[i-1])\n",
    "      except:\n",
    "        print('Error {}'.format(numeric_cols[i-1]))\n",
    "        break\n",
    "    \n",
    "_distribution_numeric(df, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee463bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_cols = df.select_dtypes('O').columns\n",
    "\n",
    "def _plot_bar_classes(df, cols):\n",
    "    df[cols].value_counts().plot.bar()\n",
    "\n",
    "def _distribution_cate(df, cate_cols, row = 1, col = 2, figsize = (20, 5)):\n",
    "  print('number of category field: ', len(cate_cols))\n",
    "  plt.figure(figsize = figsize)\n",
    "  plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.2, hspace=0.5)    \n",
    "  for i in range(1, len(cate_cols)+1, 1):\n",
    "    try:\n",
    "      plt.subplot(row, col, i)\n",
    "      _plot_bar_classes(df, cate_cols[i-1])\n",
    "      plt.title(cate_cols[i-1])\n",
    "    except:\n",
    "      break\n",
    "\n",
    "_distribution_cate(df, cate_cols, row = 4, col = 4, figsize = (30, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c14dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, stratify=df['Response'])\n",
    "\n",
    "X_train = df_train.copy()\n",
    "y_train = X_train.pop(\"Response\")\n",
    "\n",
    "X_test = df_test.copy()\n",
    "y_test = X_test.pop(\"Response\")\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0c1d9",
   "metadata": {},
   "source": [
    "+ Encode categorical features using `OneHotEncoder`\n",
    "+ Deal with missing data using `SimpleImputer`\n",
    "+ Remove outliers using `MinMaxScaler`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe11eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = list(X_train.select_dtypes('object').columns)\n",
    "num_names = list(X_train.select_dtypes(['float', 'int']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8eed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names, num_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01c21b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "cat_pl = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_pl = Pipeline(\n",
    "    steps=[\n",
    "           ('imputer', KNNImputer(n_neighbors=7)),\n",
    "           ('scaler', MinMaxScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b46ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pl, num_names), # áp dụng pipeline cho biến liên tục\n",
    "        ('cat', cat_pl, cat_names), # áp dụng pipeline cho biến phân loại\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fbfb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_pl = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ]\n",
    ")\n",
    "# training\n",
    "completed_pl.fit(X_train, y_train)\n",
    "\n",
    "# accuracy\n",
    "y_train_pred = completed_pl.predict(X_train)\n",
    "print(f\"Accuracy on train: {accuracy_score(list(y_train), list(y_train_pred)):.2f}\")\n",
    "\n",
    "y_pred = completed_pl.predict(X_test)\n",
    "print(f\"Accuracy on test: {accuracy_score(list(y_test), list(y_pred)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e2d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np\n",
    "\n",
    "def fbeta(y_true, y_pred):\n",
    "\treturn fbeta_score(y_true, y_pred, beta=np.sqrt(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914a60e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "metric = make_scorer(fbeta)\n",
    "scores = cross_val_score(completed_pl, X_train, y_train, scoring=metric, cv=cv, n_jobs=-1)\n",
    "print('Mean Fbeta: {:.03f} {:.03f}'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aa3d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "models = [GaussianNB(), LogisticRegression(), KNeighborsClassifier(), MLPClassifier(), RandomForestClassifier()]\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "all_scores = []\n",
    "for model in models:\n",
    "  completed_pl = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), ('classifier', model)]\n",
    "  )\n",
    "\n",
    "  scores = cross_val_score(completed_pl, X_train, y_train, scoring=metric, cv=cv, n_jobs=-1)\n",
    "  all_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fe73e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model_names = ['GaussianNB', 'Logistic', 'KNN', 'MLP', 'RandomForest']\n",
    "\n",
    "# Draw bboxplot \n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.boxplot(all_scores)\n",
    "plt.xlabel('Model', fontsize=16)\n",
    "plt.ylabel('Score', fontsize=16)\n",
    "plt.xticks(np.arange(len(model_names))+1, model_names, rotation=45, fontsize=16)\n",
    "plt.title(\"Scores Metrics\", fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f069838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class ClassifierSwitcher(BaseEstimator):\n",
    "  def __init__(\n",
    "      self, \n",
    "      estimator = RandomForestClassifier(),\n",
    "  ):\n",
    "      \"\"\"\n",
    "      A Custom BaseEstimator that can switch between classifiers.\n",
    "      :param estimator: sklearn object - The classifier\n",
    "      \"\"\" \n",
    "      \n",
    "      self.estimator = estimator\n",
    "\n",
    "  def fit(self, X, y=None, **kwargs):\n",
    "      self.estimator.fit(X, y)\n",
    "      return self\n",
    "\n",
    "  def predict(self, X, y=None):\n",
    "      return self.estimator.predict(X)\n",
    "\n",
    "  def predict_proba(self, X):\n",
    "      return self.estimator.predict_proba(X)\n",
    "\n",
    "  def score(self, X, y):\n",
    "      return self.estimator.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "pipeline = Pipeline(\n",
    "    steps=[(\"pre\", preprocessor), (\"clf\", ClassifierSwitcher())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {\n",
    "        'clf__estimator': [LogisticRegression()], # SVM if hinge loss / logreg if log loss\n",
    "        'clf__estimator__penalty': ('l2', 'elasticnet', 'l1'),\n",
    "        'clf__estimator__max_iter': [50, 80],\n",
    "        'clf__estimator__tol': [1e-4]\n",
    "    },\n",
    "    {\n",
    "        'clf__estimator': [RandomForestClassifier()],\n",
    "        'clf__estimator__n_estimators': [50, 100],\n",
    "        'clf__estimator__max_depth': [5, 10],\n",
    "        'clf__estimator__criterion': ('gini', 'entropy')\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9d0178",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = make_scorer(fbeta)\n",
    "gscv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=12, scoring=metric, return_train_score=True, error_score=0, verbose=3)\n",
    "gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc1200",
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef00cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f16ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0483c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
