{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2062435",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9d342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"deep\", font_scale=1.5)\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4565089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_q = pd.read_excel(\"data/TRAIN/TRAIN_QUANTITATIVE_METADATA.xlsx\")\n",
    "# train_c = pd.read_excel(\"data/TRAIN/TRAIN_CATEGORICAL_METADATA.xlsx\")\n",
    "# train_combined = pd.merge(train_q, train_c, on='participant_id', how='left').set_index(\"participant_id\") \n",
    "\n",
    "\n",
    "# test_q = pd.read_excel(\"data/TEST/TEST_QUANTITATIVE_METADATA.xlsx\")\n",
    "# test_c = pd.read_excel(\"data/TEST/TEST_CATEGORICAL_METADATA.xlsx\")\n",
    "# test_combined = pd.merge(test_q, test_c, on='participant_id', how='left').set_index(\"participant_id\")\n",
    "\n",
    "train_combined = pd.read_csv(\"train_processed.csv\").set_index(\"participant_id\")\n",
    "test_combined = pd.read_csv(\"test_processed.csv\").set_index(\"participant_id\")\n",
    "\n",
    "labels = pd.read_excel(\"data/TRAIN/TRAINING_SOLUTIONS.xlsx\").set_index(\"participant_id\")\n",
    "\n",
    "train_combined = train_combined.sort_index()\n",
    "test_combined = test_combined.sort_index()\n",
    "labels = labels.sort_index()\n",
    "\n",
    "assert all(train_combined.index == labels.index), \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa753e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bd271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = labels.copy()\n",
    "\n",
    "# Plot: ADHD_Outcome\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=label_df[\"ADHD_Outcome\"], palette=\"Set2\")\n",
    "plt.title(\"Distribution of ADHD_Outcome\")\n",
    "plt.xticks([0, 1], ['No ADHD (0)', 'ADHD (1)'])\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot: Sex_F\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=label_df[\"Sex_F\"], palette=\"pastel\")\n",
    "plt.title(\"Distribution of Sex_F\")\n",
    "plt.xticks([0, 1], ['Male (0)', 'Female (1)'])\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0eed78",
   "metadata": {},
   "source": [
    "# 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b830f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_combined.columns)\n",
    "print(len(train_combined.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df37b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "numerical_features = [\n",
    "    'EHQ_EHQ_Total', 'ColorVision_CV_Score', 'APQ_P_APQ_P_CP',\n",
    "    'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD',\n",
    "    'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP', 'SDQ_SDQ_Conduct_Problems',\n",
    "    'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems',\n",
    "    'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Generating_Impact',\n",
    "    'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing',\n",
    "    'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial', 'MRI_Track_Age_at_Scan', \n",
    "]\n",
    "print(len(numerical_features))\n",
    "\n",
    "def _plot_numeric_classes(df, col, bins=10, hist=True, kde=True):\n",
    "    if hist:\n",
    "        sns.histplot(df[col], bins=bins, kde=False)\n",
    "    if kde:\n",
    "        sns.kdeplot(df[col], color=\"red\")\n",
    "\n",
    "def _distribution_numeric(df, numeric_cols, figsize=(12, 6), bins = 10):\n",
    "    num_features = len(numeric_cols)\n",
    "\n",
    "    ncols = 4\n",
    "    nrows = math.ceil(num_features / ncols)\n",
    "\n",
    "    plt.figure(figsize = (figsize[0], nrows * (figsize[1] / 3))) # Adjust figsize based on nrows\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.2, hspace=0.5)\n",
    "\n",
    "    for i in range(num_features):\n",
    "        plt.subplot(nrows, ncols, i + 1)\n",
    "        _plot_numeric_classes(df, numeric_cols[i], bins = bins)\n",
    "        plt.title(numeric_cols[i])\n",
    "\n",
    "    plt.tight_layout() # Adjust layout to prevent titles overlapping\n",
    "    plt.show()\n",
    "    \n",
    "_distribution_numeric(train_combined, numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6386dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "'Basic_Demos_Enroll_Year', 'PreInt_Demos_Fam_Child_Ethnicity',\n",
    "'PreInt_Demos_Fam_Child_Race', 'MRI_Track_Scan_Location',\n",
    "'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ',\n",
    "'Barratt_Barratt_P2_Edu', 'Barratt_Barratt_P2_Occ',\n",
    "'Laterality_Category'\n",
    "]\n",
    "\n",
    "print(len(categorical_features))\n",
    "\n",
    "def _plot_bar_classes(df, cols):\n",
    "    df[cols].value_counts().plot.bar()\n",
    "\n",
    "def _distribution_cate(df, cate_cols, row = 1, col = 2, figsize = (20, 5)):\n",
    "  plt.figure(figsize = figsize)\n",
    "  plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.2, hspace=0.5)    \n",
    "  for i in range(1, len(cate_cols)+1, 1):\n",
    "    try:\n",
    "      plt.subplot(row, col, i)\n",
    "      _plot_bar_classes(df, cate_cols[i-1])\n",
    "      plt.title(cate_cols[i-1])\n",
    "    except:\n",
    "      break\n",
    "\n",
    "# _distribution_cate(train_combined, categorical_features, row = 3, col = 3, figsize = (12, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b32535",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined.isnull().sum().sum()\n",
    "test_combined.isnull().sum().sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2035e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', IterativeImputer(\n",
    "            estimator=LassoCV(random_state=SEED),\n",
    "            max_iter=100,\n",
    "            random_state=SEED,\n",
    "        )),\n",
    "        ('scaler', StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipeline, numerical_features),\n",
    "        ('cat', cat_pipeline, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cleaned_train = preprocessor.fit_transform(train_combined)\n",
    "# cleaned_test = preprocessor.transform(test_combined)\n",
    "print(\"Train shape: \", cleaned_train.shape)\n",
    "# print(\"Test shape: \", cleaned_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa88ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cleaned_train_df = pd.DataFrame(\n",
    "    cleaned_train,\n",
    "    columns=numerical_features + list(preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)),\n",
    "    index=train_combined.index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49469c33",
   "metadata": {},
   "source": [
    "# 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a0dd0",
   "metadata": {},
   "source": [
    "PLEASE TRAIN A DEEP NEURAL NETWORK ON THIS DATASET\n",
    "\n",
    "+ good weight initializations \n",
    "\n",
    " + K-fold cross validation with k = 10, stratified repeated fold with n_repeats = 3  \n",
    "\n",
    " + Num epochs = 100 \n",
    "\n",
    " + batch size = 64 \n",
    "\n",
    " + L2 regularization with l2 lambda = 0.01 \n",
    "\n",
    " + dropout rate = 0.3 \n",
    "\n",
    " + also add early stopping with patience = 40Â \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b79778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED) # Set TF seed for reproducibility\n",
    "np.random.seed(SEED) # Set numpy seed for other operations\n",
    "\n",
    "X = cleaned_train_df.copy()\n",
    "\n",
    "y = labels.loc[X.index, [\"ADHD_Outcome\", \"Sex_F\"]].copy()\n",
    "\n",
    "stratify_y = y['ADHD_Outcome'].astype(str) + '_' + y['Sex_F'].astype(str)\n",
    "\n",
    "X_np = X.values\n",
    "y_np = y.values\n",
    "stratify_y_np = stratify_y.values\n",
    "\n",
    "print(\"Shape of X_np (features):\", X_np.shape)\n",
    "print(\"Shape of y_np (labels):\", y_np.shape)\n",
    "print(\"Shape of stratify_y_np (stratification key):\", stratify_y_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377e327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fold_metric_corrected(y_true_fold, y_pred_proba_fold):\n",
    "    \"\"\"\n",
    "    Calculates the average of weighted F1 for ADHD and standard F1 for Sex_F for a fold.\n",
    "    Assumes y_true_fold has shape (N_fold, 2) with columns [ADHD_Outcome, Sex_F].\n",
    "    Uses default threshold of 0.5 for binary predictions.\n",
    "    \"\"\"\n",
    "    y_pred_binary_fold = (y_pred_proba_fold > 0.5).astype(int)\n",
    "\n",
    "    y_true_adhd_fold = y_true_fold[:, 0]\n",
    "    y_pred_adhd_fold = y_pred_binary_fold[:, 0]\n",
    "    y_true_sex_fold = y_true_fold[:, 1]\n",
    "    y_pred_sex_fold = y_pred_binary_fold[:, 1]\n",
    "\n",
    "    # adjusted sample weights\n",
    "    adhd_sample_weights = np.where((y_true_adhd_fold == 1) & (y_true_sex_fold == 1), 2, 1)\n",
    "\n",
    "    adhd_weighted_f1 = f1_score(y_true_adhd_fold, y_pred_adhd_fold, sample_weight=adhd_sample_weights, zero_division=0)\n",
    "    sex_f_macro_f1 = f1_score(y_true_sex_fold, y_pred_sex_fold, average='macro', zero_division=0)\n",
    "\n",
    "    average_competition_score = (adhd_weighted_f1 + sex_f_macro_f1) / 2\n",
    "    \n",
    "    return average_competition_score, adhd_weighted_f1, sex_f_macro_f1\n",
    "\n",
    "\n",
    "def create_dnn_model(input_dim, l2_lambda=0.01, dropout_rate=0.3):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),\n",
    "\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),\n",
    "\n",
    "        Dense(2, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'f1_score']) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562f119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- K-fold Cross-Validation Setup ---\n",
    "\n",
    "n_splits = 10      # Number of folds\n",
    "n_repeats = 3      # Number of repetitions\n",
    "epochs = 100       # Max epochs per fold\n",
    "batch_size = 64    # Batch size\n",
    "l2_lambda = 0.01   # L2 regularization strength\n",
    "dropout_rate = 0.3 # Dropout rate\n",
    "es_patience = 40   # Early stopping patience\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=SEED)\n",
    "\n",
    "# Lists to store metrics and OOF predictions from CV\n",
    "fold_competition_scores = []\n",
    "fold_adhd_weighted_f1s = []\n",
    "fold_sex_f_macro_f1s = []\n",
    "fold_epochs_trained = []\n",
    "\n",
    "# Lists to collect OOF predictions and corresponding true labels for threshold optimization\n",
    "oof_preds_list = []\n",
    "oof_y_true_list = []\n",
    "\n",
    "print(f\"\\n--- Starting Repeated Stratified K-Fold Cross-Validation ({n_repeats} repeats of {n_splits} folds) ---\")\n",
    "fold_count = 0\n",
    "\n",
    "# rskf.split yields integer indices referencing the rows of X_np and y_np\n",
    "for train_index, val_index in rskf.split(X_np, stratify_y_np):\n",
    "    fold_count += 1\n",
    "    print(f\"\\n--- Fold {fold_count}/{n_splits * n_repeats} ---\")\n",
    "\n",
    "    # Split data for the current fold using integer indices\n",
    "    X_train_fold, X_val_fold = X_np[train_index], X_np[val_index]\n",
    "    y_train_fold, y_val_fold = y_np[train_index], y_np[val_index] # y_np has shape (N, 2)\n",
    "\n",
    "    # Create a new model instance for each fold to ensure fresh weights\n",
    "    model = create_dnn_model(input_dim=X_train_fold.shape[1], l2_lambda=l2_lambda, dropout_rate=dropout_rate)\n",
    "\n",
    "    # Define Early Stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=es_patience, restore_best_weights=True)\n",
    "\n",
    "    print(f\"Training model for Fold {fold_count}...\")\n",
    "    # Train the model on the training portion of the fold\n",
    "    history = model.fit(X_train_fold, y_train_fold,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(X_val_fold, y_val_fold), # Evaluate on the validation portion\n",
    "                        callbacks=[early_stopping],\n",
    "                        verbose=0) # Set verbose=1 to see training progress per epoch\n",
    "\n",
    "    epochs_ran = len(history.history['loss'])\n",
    "    print(f\"Finished training for Fold {fold_count}. Epochs trained: {epochs_ran}\")\n",
    "    fold_epochs_trained.append(epochs_ran)\n",
    "\n",
    "    # --- Evaluate on the Validation Fold using the Competition Metric (Default Threshold 0.5) ---\n",
    "    print(\"Evaluating on validation fold (using default 0.5 threshold)...\")\n",
    "    # Predict probabilities on the validation fold data\n",
    "    val_preds_proba = model.predict(X_val_fold)\n",
    "\n",
    "    # Calculate the custom competition metric with default 0.5 threshold\n",
    "    fold_comp_score, fold_adhd_w_f1, fold_sex_f_f1 = calculate_fold_metric_corrected(\n",
    "        y_val_fold,      # Pass true labels for the fold (contains ADHD and Sex_F)\n",
    "        val_preds_proba  # Pass predicted probabilities for the fold\n",
    "    )\n",
    "\n",
    "    print(f\"Fold {fold_count} Metrics (Default 0.5 Threshold):\")\n",
    "    print(f\"  Weighted ADHD F1: {fold_adhd_w_f1:.4f}\")\n",
    "    print(f\"  Sex_F Macro F1:   {fold_sex_f_f1:.4f}\")\n",
    "    print(f\"  Competition Avg F1: {fold_comp_score:.4f}\")\n",
    "\n",
    "    # Store fold metrics\n",
    "    fold_competition_scores.append(fold_comp_score)\n",
    "    fold_adhd_weighted_f1s.append(fold_adhd_w_f1)\n",
    "    fold_sex_f_macro_f1s.append(fold_sex_f_f1)\n",
    "\n",
    "    # --- Collect OOF Predictions and True Labels ---\n",
    "    # Store the predictions and true labels for this validation fold\n",
    "    oof_preds_list.append(val_preds_proba)\n",
    "    oof_y_true_list.append(y_val_fold)\n",
    "\n",
    "\n",
    "print(\"\\n--- Cross-Validation Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da92a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Aggregate OOF Predictions and True Labels ---\n",
    "# Concatenate predictions and true labels from all validation folds\n",
    "# Note: With Repeated KFold, samples appear multiple times. This is fine for\n",
    "# threshold optimization, but you'd handle duplicates if building a single OOF\n",
    "# prediction set for ensembling or final evaluation.\n",
    "all_oof_preds = np.concatenate(oof_preds_list, axis=0)\n",
    "all_oof_y_true = np.concatenate(oof_y_true_list, axis=0)\n",
    "\n",
    "print(f\"\\nAggregated OOF predictions shape: {all_oof_preds.shape}\")\n",
    "print(f\"Aggregated OOF true labels shape: {all_oof_y_true.shape}\")\n",
    "\n",
    "\n",
    "avg_comp_score_default_thresh = np.mean(fold_competition_scores)\n",
    "std_comp_score_default_thresh = np.std(fold_competition_scores)\n",
    "avg_adhd_w_f1_default_thresh = np.mean(fold_adhd_weighted_f1s)\n",
    "std_adhd_w_f1_default_thresh = np.std(fold_adhd_weighted_f1s)\n",
    "avg_sex_f_f1_default_thresh = np.mean(fold_sex_f_macro_f1s)\n",
    "std_sex_f_f1_default_thresh = np.std(fold_sex_f_macro_f1s)\n",
    "avg_epochs = np.mean(fold_epochs_trained)\n",
    "\n",
    "print(\"\\n--- Cross-Validation Results Summary (Default 0.5 Threshold) ---\")\n",
    "print(f\"Total Folds Run: {fold_count}\")\n",
    "print(f\"Average Epochs Trained per Fold: {avg_epochs:.1f}\")\n",
    "print(\"\\nAverage Metrics Across All Folds:\")\n",
    "print(f\"  Weighted ADHD F1: {avg_adhd_w_f1_default_thresh:.4f} +/- {std_adhd_w_f1_default_thresh:.4f}\")\n",
    "print(f\"  Sex_F Macro F1:   {avg_sex_f_f1_default_thresh:.4f} +/- {std_sex_f_f1_default_thresh:.4f}\")\n",
    "print(f\"  Competition Avg F1: {avg_comp_score_default_thresh:.4f} +/- {std_comp_score_default_thresh:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadabdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Threshold Optimization on OOF Predictions ---\n",
    "\n",
    "print(\"\\n--- Starting Threshold Optimization on OOF Data ---\")\n",
    "\n",
    "# Define the metric function for OOF data using specific thresholds\n",
    "def calculate_oof_metric_with_thresholds(y_true_oof, y_pred_proba_oof, adhd_threshold, sex_f_threshold):\n",
    "    \"\"\"\n",
    "    Calculates the competition metric on OOF data using specific thresholds.\n",
    "    \"\"\"\n",
    "    # Create a binary prediction array based on the specified thresholds\n",
    "    y_pred_binary_oof = np.zeros_like(y_pred_proba_oof, dtype=int)\n",
    "    y_pred_binary_oof[:, 0] = (y_pred_proba_oof[:, 0] > adhd_threshold).astype(int) # Threshold for ADHD\n",
    "    y_pred_binary_oof[:, 1] = (y_pred_proba_oof[:, 1] > sex_f_threshold).astype(int) # Threshold for Sex_F\n",
    "\n",
    "    # Extract true and predicted labels for each outcome\n",
    "    y_true_adhd = y_true_oof[:, 0]\n",
    "    y_pred_adhd = y_pred_binary_oof[:, 0]\n",
    "    y_true_sex = y_true_oof[:, 1]\n",
    "    y_pred_sex = y_pred_binary_oof[:, 1]\n",
    "\n",
    "    # Weighted F1 for ADHD (uses true Sex_F label for weight)\n",
    "    adhd_sample_weights = np.where((y_true_adhd == 1) & (y_true_sex == 1), 2, 1)\n",
    "    adhd_weighted_f1 = f1_score(y_true_adhd, y_pred_adhd, sample_weight=adhd_sample_weights, zero_division=0)\n",
    "\n",
    "    # Macro F1 for Sex_F\n",
    "    sex_f_macro_f1 = f1_score(y_true_sex, y_pred_sex, average='macro', zero_division=0)\n",
    "\n",
    "    # Competition metric is the average of the two F1 scores\n",
    "    return (adhd_weighted_f1 + sex_f_macro_f1) / 2\n",
    "\n",
    "# Grid search for the best thresholds\n",
    "# Search range: from 0.05 to 0.95 with a step (adjust range and step as needed for thoroughness vs speed)\n",
    "threshold_range = np.arange(0.05, 0.96, 0.01) # Example range, adjust if necessary\n",
    "\n",
    "best_oof_score = -1 # Initialize with a score lower than any possible F1\n",
    "best_adhd_thresh = 0.5 # Default starting point\n",
    "best_sex_f_thresh = 0.5 # Default starting point\n",
    "\n",
    "print(f\"Searching thresholds from {threshold_range[0]:.2f} to {threshold_range[-1]:.2f} with step {threshold_range[1]-threshold_range[0]:.2f}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b778ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all combinations of thresholds\n",
    "# Warning: This nested loop can take significant time depending on the size of threshold_range\n",
    "for adhd_thresh in threshold_range:\n",
    "    for sex_f_thresh in threshold_range:\n",
    "        # Calculate the competition score for the current threshold pair on OOF data\n",
    "        score = calculate_oof_metric_with_thresholds(all_oof_y_true, all_oof_preds, adhd_thresh, sex_f_thresh)\n",
    "\n",
    "        # Update best score and thresholds if current score is higher\n",
    "        if score > best_oof_score:\n",
    "            best_oof_score = score\n",
    "            best_adhd_thresh = adhd_thresh\n",
    "            best_sex_f_thresh = sex_f_thresh\n",
    "\n",
    "print(\"\\n--- Threshold Optimization Complete ---\")\n",
    "print(f\"Best OOF Competition Score Found: {best_oof_score:.4f}\")\n",
    "print(f\"Optimal ADHD Threshold: {best_adhd_thresh:.4f}\")\n",
    "print(f\"Optimal Sex_F Threshold: {best_sex_f_thresh:.4f}\")\n",
    "print(f\"Improvement over Default 0.5 Threshold: {best_oof_score - avg_comp_score_default_thresh:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79648979",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_test = preprocessor.transform(test_combined)\n",
    "\n",
    "num_cols_out = [col for col in numerical_features] \n",
    "cat_transformer = preprocessor.named_transformers_['cat']\n",
    "cat_cols_out = cat_transformer.named_steps['onehot'].get_feature_names_out(categorical_features)\n",
    "\n",
    "all_cols_out = list(num_cols_out) + list(cat_cols_out)\n",
    "\n",
    "cleaned_test_df = pd.DataFrame(\n",
    "    cleaned_test,\n",
    "    columns=all_cols_out,\n",
    "    index=test_combined.index # Use the original test participant_ids as index\n",
    ")\n",
    "\n",
    "X_test_np = cleaned_test_df.values\n",
    "\n",
    "print(\"Shape of preprocessed test data (cleaned_test_df):\", cleaned_test_df.shape)\n",
    "print(\"Shape of test data numpy array (X_test_np):\", X_test_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ab9fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train Final Model on Entire Training Data ---\n",
    "\n",
    "print(\"\\n--- Training Final Model on Entire Training Data ---\")\n",
    "\n",
    "# Create the final model instance with the same architecture and hyperparameters\n",
    "final_model = create_dnn_model(input_dim=X_np.shape[1], l2_lambda=l2_lambda, dropout_rate=dropout_rate)\n",
    "\n",
    "# Train for the average number of epochs found during CV\n",
    "# Use np.ceil to round up, ensure at least 1 epoch\n",
    "final_epochs = max(1, int(np.ceil(avg_epochs)))\n",
    "\n",
    "print(f\"Training final model for {final_epochs} epochs on the entire training dataset ({X_np.shape[0]} samples)...\")\n",
    "\n",
    "# Train the model on the full training data (features X_np, labels y_np)\n",
    "# Use verbose=1 to show the training progress\n",
    "final_model.fit(X_np, y_np,\n",
    "                epochs=final_epochs,\n",
    "                batch_size=batch_size, # Use the same batch size as in CV\n",
    "                verbose=1)\n",
    "\n",
    "test_predictions_proba = final_model.predict(X_test_np)\n",
    "\n",
    "# test_predictions_proba has shape (Number of test samples, 2)\n",
    "# Column 0 is the predicted probability for ADHD_Outcome=1\n",
    "# Column 1 is the predicted probability for Sex_F=1\n",
    "print(\"Shape of test predictions (probabilities):\", test_predictions_proba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da4af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume all previous code including threshold optimization is executed,\n",
    "# and best_adhd_thresh and best_sex_f_thresh are available.\n",
    "# Assume test_predictions_proba is available from model.predict(X_test_np).\n",
    "# Assume test_combined is available with participant_id as index.\n",
    "\n",
    "# --- Create Submission File (using BINARY predictions with optimal thresholds) ---\n",
    "\n",
    "print(\"\\n--- Creating Submission File (Binary Predictions) ---\")\n",
    "\n",
    "# Get the participant_ids from the original test data (its index)\n",
    "test_participant_ids = test_combined.index\n",
    "\n",
    "# --- Apply the optimal thresholds to convert probabilities to binary predictions ---\n",
    "# These thresholds (best_adhd_thresh, best_sex_f_thresh) were found\n",
    "# by optimizing the competition metric on the OOF validation data.\n",
    "test_predictions_binary = np.zeros_like(test_predictions_proba, dtype=int)\n",
    "\n",
    "# Apply the optimal threshold for ADHD predictions\n",
    "test_predictions_binary[:, 0] = (test_predictions_proba[:, 0] > best_adhd_thresh).astype(int)\n",
    "\n",
    "# Apply the optimal threshold for Sex_F predictions\n",
    "test_predictions_binary[:, 1] = (test_predictions_proba[:, 1] > best_sex_f_thresh).astype(int)\n",
    "\n",
    "# --- Create a Pandas DataFrame for the submission file ---\n",
    "# The submission format now requires binary values (0 or 1) for ADHD_Outcome and Sex_F\n",
    "submission_df = pd.DataFrame({\n",
    "    'participant_id': test_participant_ids,\n",
    "    'ADHD_Outcome': test_predictions_binary[:, 0], # Use the binarized ADHD predictions\n",
    "    'Sex_F': test_predictions_binary[:, 1]        # Use the binarized Sex_F predictions\n",
    "})\n",
    "\n",
    "# Ensure the columns are in the exact required order: participant_id,ADHD_Outcome,Sex_F\n",
    "submission_df = submission_df[['participant_id', 'ADHD_Outcome', 'Sex_F']]\n",
    "\n",
    "# Print the head of the submission DataFrame to verify the format\n",
    "# It should now show 0s and 1s in the prediction columns.\n",
    "print(\"\\nSubmission file head (Binary Predictions):\")\n",
    "print(submission_df.head())\n",
    "\n",
    "# --- Save the submission DataFrame to a CSV file ---\n",
    "submission_filename = \"submission.csv\"\n",
    "# Use index=False to prevent writing the DataFrame index as a column\n",
    "# The default separator for .to_csv is comma, which is correct.\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"\\nSubmission file successfully created with binary predictions and saved as '{submission_filename}'\")\n",
    "\n",
    "# Note: The raw probabilities from model.predict() were thresholded using\n",
    "# the optimal thresholds found on the OOF validation data to produce these\n",
    "# binary outputs for the submission file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
