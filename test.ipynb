{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8734d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import brier_score_loss, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")\n",
    "\n",
    "SEED = 42\n",
    "FOLDS = 5\n",
    "\n",
    "# %% [code]\n",
    "# Load data\n",
    "train_combined = pd.read_csv(\"train_processed.csv\").set_index(\"participant_id\")\n",
    "test_combined = pd.read_csv(\"test_processed.csv\").set_index(\"participant_id\")\n",
    "labels = pd.read_excel(\"data/TRAIN/TRAINING_SOLUTIONS.xlsx\").set_index(\"participant_id\")\n",
    "\n",
    "# Make sure the indices are sorted and aligned\n",
    "train_combined = train_combined.sort_index()\n",
    "labels = labels.sort_index()\n",
    "assert all(train_combined.index == labels.index), \"Label IDs do not match train IDs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7471ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Define a helper function for additional feature engineering. \n",
    "def add_new_features(df):\n",
    "    epsilon = 1e-5\n",
    "    # --- Features based on high correlation analysis ---\n",
    "    # Interaction: product of SDQ hyperactivity and externalizing\n",
    "    df['I_Hyper_External'] = df['SDQ_SDQ_Hyperactivity'] * df['SDQ_SDQ_Externalizing']\n",
    "    \n",
    "    # Difference: externalizing minus internalizing\n",
    "    df['Diff_External_Internal'] = df['SDQ_SDQ_Externalizing'] - df['SDQ_SDQ_Internalizing']\n",
    "    \n",
    "    # Ratio: externalizing divided by internalizing (avoid division by zero)\n",
    "    df['Ratio_External_Internal'] = df['SDQ_SDQ_Externalizing'] / (df['SDQ_SDQ_Internalizing'] + epsilon)\n",
    "    \n",
    "    # Composite score: average of hyperactivity, externalizing, and emotional problems\n",
    "    df['Composite_SDQ'] = (df['SDQ_SDQ_Hyperactivity'] + \n",
    "                           df['SDQ_SDQ_Externalizing'] + \n",
    "                           df['SDQ_SDQ_Emotional_Problems']) / 3.0\n",
    "    # Log transform to reduce skewness\n",
    "    df['Log_Composite_SDQ'] = np.log1p(df['Composite_SDQ'])\n",
    "    \n",
    "    # --- Domain knowledge based features ---\n",
    "    # Age-adjusted hyperactivity score (if age is available)\n",
    "    if 'MRI_Track_Age_at_Scan' in df.columns:\n",
    "        df['Age_Adjusted_Hyperactivity'] = df['SDQ_SDQ_Hyperactivity'] / (df['MRI_Track_Age_at_Scan'] + epsilon)\n",
    "    \n",
    "    # Enrollment year effects (if available)\n",
    "    if 'Basic_Demos_Enroll_Year' in df.columns:\n",
    "        df['Relative_Enroll_Year'] = df['Basic_Demos_Enroll_Year'] - df['Basic_Demos_Enroll_Year'].min()\n",
    "        # Optionally create bins (for example, Early, Mid, Late)\n",
    "        df['Enroll_Year_Bin'] = pd.cut(df['Basic_Demos_Enroll_Year'], bins=3, labels=[1, 2, 3])\n",
    "    \n",
    "    # Interaction between parenting score and composite SDQ score\n",
    "    if 'APQ_P_APQ_P_ID' in df.columns:\n",
    "        df['Parent_Behavior_Interaction'] = df['APQ_P_APQ_P_ID'] * df['Composite_SDQ']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering to both training and test sets\n",
    "# train_combined = add_new_features(train_combined)\n",
    "# test_combined = add_new_features(test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a752168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features (we use StandardScaler)\n",
    "scaler = StandardScaler()\n",
    "train_combined = pd.DataFrame(scaler.fit_transform(train_combined), \n",
    "                              columns=train_combined.columns, index=train_combined.index)\n",
    "test_combined = pd.DataFrame(scaler.transform(test_combined), \n",
    "                             columns=test_combined.columns, index=test_combined.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47fab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Define target variables\n",
    "y_adhd = labels['ADHD_Outcome']\n",
    "y_sex = labels['Sex_F']\n",
    "# Create a combined string indicator (e.g., \"11\" for female ADHD) for later use if needed\n",
    "combinations = y_adhd.astype(str) + y_sex.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f933e19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for ADHD prediction (including newly engineered features)\n",
    "features_adhd = [\n",
    "    'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Difficulties_Total', \n",
    "    'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Internalizing', \n",
    "    'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Prosocial', \n",
    "    'Basic_Demos_Enroll_Year', 'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_ID',\n",
    "    #### New Features ####\n",
    "    'I_Hyper_External', 'Diff_External_Internal', 'Ratio_External_Internal', \n",
    "    'Composite_SDQ', 'Log_Composite_SDQ', 'Enroll_Year_Bin', 'Relative_Enroll_Year',\n",
    "    'Parent_Behavior_Interaction'\n",
    "]\n",
    "interactions = ['SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Peer_Problems', 'Basic_Demos_Enroll_Year', 'APQ_P_APQ_P_ID']\n",
    "\n",
    "features_sex = [\n",
    "    'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Prosocial', 'SDQ_SDQ_Externalizing', \n",
    "    'SDQ_SDQ_Emotional_Problems', 'ColorVision_CV_Score', 'APQ_P_APQ_P_PP', \n",
    "    'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD', 'SDQ_SDQ_Internalizing', 'adhd_proba'\n",
    "] + [f\"I_{feat}\" for feat in interactions] + ['Parent_Behavior_Interaction', 'Relative_Enroll_Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5935074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Define a custom threshold optimizer that wraps a base classifier.\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "\n",
    "class ThresholdOptimizer(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator, threshold=0.5, optimize=True):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.threshold = threshold\n",
    "        self.optimize = optimize\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.base_estimator_ = clone(self.base_estimator)\n",
    "        self.base_estimator_.fit(X, y)\n",
    "        if self.optimize:\n",
    "            y_pred_proba = self.base_estimator_.predict_proba(X)[:, 1]\n",
    "            best_thresh = 0.5\n",
    "            best_score = 0\n",
    "            # Sweep through a range of thresholds to maximize F1 score\n",
    "            for t in np.linspace(0.1, 0.9, 81):\n",
    "                score = f1_score(y, (y_pred_proba > t).astype(int))\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_thresh = t\n",
    "            self.threshold = best_thresh\n",
    "            print(f\"Optimized threshold: {self.threshold:.2f} (F1: {best_score:.4f})\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.base_estimator_.predict_proba(X)[:, 1]\n",
    "        return (proba > self.threshold).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.base_estimator_.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadbbabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a StratifiedKFold for tuning.\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Pipeline for ADHD prediction.\n",
    "pipeline_adhd = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', ThresholdOptimizer(\n",
    "        base_estimator=LogisticRegression(\n",
    "            solver='saga',\n",
    "            class_weight='balanced',\n",
    "            random_state=SEED,\n",
    "            fit_intercept=True\n",
    "        ),\n",
    "        optimize=True\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Parameter grid for ADHD pipeline (tuning LogisticRegression hyperparameters)\n",
    "param_grid_adhd = {\n",
    "    'model__base_estimator__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'model__base_estimator__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "grid_search_adhd = GridSearchCV(\n",
    "    pipeline_adhd,\n",
    "    param_grid=param_grid_adhd,\n",
    "    scoring='f1',\n",
    "    cv=skf,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea70d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ADHD model using training data\n",
    "grid_search_adhd.fit(train_combined[features_adhd], y_adhd)\n",
    "print(\"Best ADHD model parameters:\", grid_search_adhd.best_params_)\n",
    "print(\"Best cross-validated F1 for ADHD:\", grid_search_adhd.best_score_)\n",
    "print(\"Optimized ADHD threshold:\", grid_search_adhd.best_estimator_.named_steps['model'].threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a8932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict ADHD probabilities on train and test data using the tuned ADHD pipeline.\n",
    "train_adhd_proba = grid_search_adhd.predict_proba(train_combined[features_adhd])[:, 1]\n",
    "test_adhd_proba = grid_search_adhd.predict_proba(test_combined[features_adhd])[:, 1]\n",
    "\n",
    "# For later use in the Sex model, add the ADHD probability as a new feature.\n",
    "train_combined['adhd_proba'] = train_adhd_proba\n",
    "test_combined['adhd_proba'] = test_adhd_proba\n",
    "\n",
    "# Also create interaction features for Sex prediction based on ADHD probability.\n",
    "for feat in interactions:\n",
    "    train_combined[f\"I_{feat}\"] = train_combined[feat] * train_combined[\"adhd_proba\"]\n",
    "    test_combined[f\"I_{feat}\"] = test_combined[feat] * test_combined[\"adhd_proba\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c652193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Build a similar pipeline for Sex prediction.\n",
    "pipeline_sex = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', ThresholdOptimizer(\n",
    "        base_estimator=LogisticRegression(\n",
    "            solver='saga',\n",
    "            class_weight='balanced',\n",
    "            random_state=SEED,\n",
    "            fit_intercept=True\n",
    "        ),\n",
    "        optimize=True\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Parameter grid for Sex pipeline.\n",
    "param_grid_sex = {\n",
    "    'model__base_estimator__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'model__base_estimator__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "grid_search_sex = GridSearchCV(\n",
    "    pipeline_sex,\n",
    "    param_grid=param_grid_sex,\n",
    "    scoring='f1',\n",
    "    cv=skf,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a0b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Sex model using the updated train data (including ADHD probability and interactions)\n",
    "grid_search_sex.fit(train_combined[features_sex], y_sex)\n",
    "print(\"Best Sex model parameters:\", grid_search_sex.best_params_)\n",
    "print(\"Best cross-validated F1 for Sex:\", grid_search_sex.best_score_)\n",
    "print(\"Optimized Sex threshold:\", grid_search_sex.best_estimator_.named_steps['model'].threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Predict Sex probabilities on the test set.\n",
    "test_sex_proba = grid_search_sex.predict_proba(test_combined[features_sex])[:, 1]\n",
    "\n",
    "# For submission, you can produce binary predictions based on the optimized thresholds:\n",
    "final_adhd_preds = grid_search_adhd.predict(test_combined[features_adhd])\n",
    "final_sex_preds = grid_search_sex.predict(test_combined[features_sex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1959d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Create a submission DataFrame using test_combined index and the predictions.\n",
    "submission = pd.DataFrame({\n",
    "    \"participant_id\": test_combined.index,\n",
    "    \"ADHD_Outcome\": final_adhd_preds,  # or use test_adhd_proba if probability submission is desired\n",
    "    \"Sex_F\": final_sex_preds           # or use test_sex_proba if probability submission is desired\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv(\"submission1.csv\", index=False)\n",
    "print(\"Submission file 'submission.csv' created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
